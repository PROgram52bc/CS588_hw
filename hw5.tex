\documentclass[12pt]{article}
\usepackage{amsmath, amssymb}
\usepackage[ruled,vlined,linesnumbered,noend]{algorithm2e}
\usepackage{dsfont}
\usepackage{fancyhdr}
\usepackage{amsthm}

\newcommand{\hw}{CS 588: Homework 5}
\newcommand{\me}{David Deng}

\pagestyle{fancy}

\fancyhf{} % clear all header/footer fields

% Optional thin rule above the footer (comment out if you don't want it)
\renewcommand{\footrulewidth}{0.4pt}

\fancyfoot[L]{\hw}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{\me}

% Ensure chapter/section opening pages also use the same footer (for classes that use 'plain' style)
\fancypagestyle{plain}{%
\fancyfoot[L]{\hw}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{\me}
}

\begin{document}
\section*{Exercise 17.1}

\begin{proof}

Define the bad event as $A_i \overset{\text{def}}{=}$ the event that the hyper
edge $i$ is monochromatic.

Define $x(A_i) = \frac{1}{1+d}$, and we observe that for each hyperedge, there
are at most $k$ incident vertices, and for each of those $k$ vertices, there are
at most $k-1$ other hyper edges. So for any edge $i$, it depends on at most
$k(k-1)$ other hyper edges. Thus $d \le k(k-1)$.

Let $Y_i(c)$ be the event that all vertices incident to edge $i$ has color $c$,
then if we randomly sample colors for each of the $k$ vertices incident to edge
$i$, for some $c \in \{0,1\}$, $\Pr[Y_i(c)] = (1/2)^k$, the chance that the
hyperedge is monochromatic is 

$$\Pr[A_i] = \Pr[Y_i(0) \lor Y_i(1)] \le \Pr[Y_i(0)] + \Pr[Y_i(1)] = (1/2)^{k-1}$$

By corollary 17.3, we know that if $e\Pr[A_i](k(k-1)+1) \le 1$, then
$\Pr[\bar{A_1}, \cdots, \bar{A_n}] > 0$, meaning the coloring is
possible.

Rearranging the condition and substituting the values, we have

\[
\begin{array}{rll}
    LHS &=& e(1/2)^{k-1}(k(k-1)+1) \\
    &=& \frac{e(k(k-1)+1)}{2^{k-1}} \\
    &=& \frac{e(k^2 - k + 1)}{2^{k-1}} \\
    &\le& 1
\end{array}
\]

Rearranging, it suffices to have

$$ k^2-k+1 \le 2^{k-1}/e$$

For $k = 8$, we have $LHS \approx 57$ and $RHS \approx 47$, where the inequality doesn't hold.
For $k = 9$, we have $LHS \approx 73$ and $RHS \approx 94$, where the inequality holds.

Since RHS has exponential growth which is faster than polynomial growth in LHS, for all $k > 9$, this inequality holds.
\end{proof}


\newpage
\section*{Exercise 19.2}

\begin{proof}
We prove the claim by contradiction. Suppose otherwise, and let $x_v <
n^{-(n+1)}$, then by stationary distribution, we have $\sum_{i\neq v} x_i \ge
1-n^{-(n+1)}$.

Further, let $u$ be the heaviest vertex in the graph, and by definition, $w(u)
\ge \frac{1-n^{-(n+1)}}{n-1}$.

Since $G$ is a strongly connected graph, there is a shortest path of length
$\ell \le n-1$ from $u$ to $v$ that contains no cycle (if there are cycles, we
remove the cycle and get a shorter path). Let the path be $(u, s_1, \cdots,
s_{\ell-1}, v)$ for some $\ell \le n-1$.

Since $G$ is a simple graph, each step of the random walk will ``pass along''
the flow to its neighboring vertices evenly, and since each vertex has at most
$n-1$ neighbors, the fractional amount is at least $\frac{1}{n-1}$.

This is also true for $u$. Define $\Delta_{ut}$ as the amount of flow passed
from $u$ to $t$ by one step of the random walk, then we have
$$\Delta{us_k} = w(u) (\frac{1}{n-1})^k \ge \frac{1-n^{-(n+1)}}{n-1} (\frac{1}{n-1})^k$$

for some $s_k$ where there is a path of length $k$ from $u$ to $s_k$.

\[
\begin{array}{rll}
\Delta_{uv} & =   & w(u) (\frac{1}{n-1})^\ell\\
            & \ge & w(u) (\frac{1}{n-1})^{n-1}\\
            & \ge & \frac{1-n^{-(n+1)}}{n-1} (\frac{1}{n-1})^{n-1}\\
            & = & \frac{n^{n+1}-1}{n^{n+1}} (\frac{1}{n-1})^{n}\\
            & = & \frac{1}{n^{n+1}} \frac{n^{n+1}-1}{(n-1)^{n}}\\
            & = & \frac{1}{n^{n+1}} \frac{n\cdot n^{n}-1}{(n-1)^{n}}\\
            & = & \frac{1}{n^{n+1}} \frac{n^{n} + (n-1)n^n -1}{(n-1)^{n}}\\
            & \ge & \frac{1}{n^{n+1}} \frac{n^{n}}{(n-1)^{n}}\\
            & \ge & \frac{1}{n^{n+1}}
\end{array}
\]

\end{proof}

\newpage
\section*{Exercise 20.3}

\begin{proof}
 
Let $G = (V,E)$ be a directed graph such that $s \in V$ and $t \in V$.  We
construct edges among the $n=\vert V\vert$ vertices as such: 
\begin{enumerate}

    \item Add $n-1$ directed edges $(s,v_1), (v_1,v_2), \cdots, (v_{n-2}, t)$
    for vertices $s,t \notin \{v_1, \cdots, v_{n-2}\}$, such that there is a
    path of length $n-1$ from $s$ to $t$.

    \item Furthermore, for every vertices $v \ne s$, add an edge $(v,s)$. 

\end{enumerate}

Since there is a path from $s$ to every vertex, and a path from every vertex to
$s$, $G$ is a strongly connected graph. Since there are no edges connecting to
the same vertex or multiple edges between the same pair of vertices, $G$ is also
a simple graph by construction.

Observe that for every vertex $v \notin \{s,t\}$, a random walk from $v$ has
$1/2$ chance of getting one step closer to $t$, and $1/2$ chance of going back
to $s$, where we'd have to start over again.

A successful random walk from $s$ to $t$ can be seen as tossing $n-2$ heads in a row, which has a probability of $p=\frac{1}{2^{n-2}}$.
Since each time we fail, we start from $s$ again, the random walk can be seen as bernoulli trials with probability $p=\frac{1}{2^{n-2}}$. 
Let $X$ be a random variable representing the number of trials till the first succcess, we have

$$\mathbb{E}[X] = 1/p = 2^{n-2}$$

which is exponential in $n$.

\end{proof}


% For directed graphs, we can compute the hitting times as follow:

% $$H(u,u) = 0$$
% $$H(u,t) = 1 + \frac{1}{\deg^+(u)} \sum_{(u,v) \in E} H(v,t)$$

% Let $v_i \notin \{s,t\}$, then we have $H(v_i, t) = 1 + \frac{1}{2} \bigl( H(s,t) + H(v_{i+1}, t)\bigr)$ and 

% Thus, we can write $H(s,t)$ as a recurrence:

% \[
% \begin{array}{rll}
%     H(s,t) & =\ & 1 + H(v_1, t) \\ 
%     & =\ & 1 + 1 + \frac{1}{2} \bigl( H(s,t) + H(v_2, t)\bigr) 
% \end{array}
% \]

% We have $H(s,v_1) = 1 + \frac{1}{2} (H)$

% Now what to do? How to lower-bound the hitting time?

\newpage
\section*{Exercise 20.5}

\begin{proof}

Define a product-graph $G^2 = (V^2,E^2)$, where 
$V^2 = \{ (v_1,v_2) \ \vert \ v_1, v_2 \in V \}$ and
$E^2 = \{ \{ (v_1, v_2), (v_1', v_2') \} \ \vert \ (v_1, v_2), (v_1', v_2') \in E \}$

First observe that the number of vertices in the product graph $\vert V^2 \vert
= \vert V \vert^2 = n^2$, as for $n$ vertices, there are $n^2$ ordered pairs.

For the number of edges in the product graph, we observe that there are $\vert
E^2 \vert = \vert E \vert^2 = m^2$ \textit{ordered pairs} of edges in the
original graph. We also observe that each ordered pair of edges $((v_1, v_2),
(v_1', v_2'))$ in the original graph (we can interpret $v_1$ and $v_2$ as a step
of random walk by Alice, and $v_1'$ and $v_2'$ by Bob, thus they are ordered),
form exactly new two edges in the product graph: $\{ (v_1, v_1'), (v_2, v_2')
\}$ and $\{ (v_2, v_1'), (v_1, v_2') \}$ (Alice and Bob either move in the same
direction or the opposite direction).

Thus, in the product graph, there are $2m^2$ edges in total.

By Lemma 20.12, if $e = (s,t) \in E$, then $$H(s,t) + H(t,s) \le 2m$$

where $m$ is the number of edges in the graph, and $s$,$t$, are vertices in the graph.

Since there is an $\ell$-edge walk from $s$ to $x$: $(s_{x1}, \cdots,
s_{x\ell})$ and from $t$ to $x$ $(t_{x1}, \cdots, t_{x\ell})$, in the product
graph, there is an $\ell$-edge walk from $(s,t)$ to $(x,x)$: $((s_{x1}, t_{x1}),
\cdots, (s_{x\ell}, t_{x\ell}))$, representing a walk where Alice and Bob meets.

Since the path from $(s,t)$ to $(x,x)$ is of length $\ell$, we have 

$$H((s,t),(x,x)) \le H((s,t),(x,x)) + H((x,x), (s,t)) \le 2 \cdot 2m^2\ell = 4m^2\ell$$
\end{proof}

\newpage
\section*{Exercise 21.7}

\begin{proof}
    
Let the initial distribution be $\mathds{1}_v$ where $v$ is the vertex in $G$ with the maximum weighted degree.
Then according to the proof of Lemma 21.10, 

we have \[
\begin{array}{rll}
    \| R^k x - \frac{1}{2W}d \|^2 &=& \|D^{1/2}SD^{-1/2}x\|^2 \\
    &\le& \max\{\mu_2^{2k},\mu_n^{2k}\} \Delta_{max}\langle x, D^{-1} x\rangle \\
    &\overset{(1)}{=}& \max\{\mu_2^{2k},\mu_n^{2k}\} \Delta_{max} \frac{1}{d(v)} \\
    &\overset{(2)}{=}& \max\{\mu_2^{2k},\mu_n^{2k}\} \Delta_{max} \frac{1}{\Delta_{max}} \\
    &=& \max\{\mu_2^{2k},\mu_n^{2k}\} \\
    &=& \max\{\mu_2,\vert \mu_n\vert \}^{2k}
\end{array}
\]
where (1) is because $D$ is a diagonal matrix of the vertex degrees, and $x = \mathds{1}_v$
(2) is because $v$ is the vertex with maximum weighted degree.

Thus, $\| R^kx-s \| = \| R^kx- \frac{1}{2w}d \| \le \max\{\mu_2, \vert \mu_n\vert \}^k = (1-\gamma)^k$

\end{proof}

\end{document}